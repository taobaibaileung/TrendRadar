# TrendRadar v2.0 - 智能信息雷达 (Obsidian 插件版)

TrendRadar 现已全面升级，为您带来更强大、更智能、更易用的信息追踪与分析体验。新版完全聚焦于 Obsidian 生态，通过一个功能完善的插件，将多源信息获取、AI 智能分析、个性化内容过滤与无缝的笔记体验融为一体。

## ✨ 核心功能

### 1. 多源信息聚合

*   **数据源分组管理**：将数据源按主题分组管理（如"科技新闻"、"行业动态"），每个分组可以独立配置 AI 服务和处理策略。
*   **图形化配置**：告别复杂的配置文件，直接在 Obsidian 设置中添加、编辑和管理您的信息源。
*   **多种数据源**：
    *   **RSS 订阅**：支持标准 RSS/Atom feeds
    *   **网站内容抓取**：通过 CSS 选择器抓取任意网站内容
    *   **Twitter/X 追踪**：追踪指定账号的最新推文
    *   **本地文件**：监听本地 Markdown 和 TXT 文件变化
*   **高度自定义**：为每个数据源独立设置更新频率 (Cron 表达式)、数据保留时长、抓取数量等高级选项。

### 2. 智能内容处理

*   **AI 驱动分析**：自动提取每条信息的关键词、分类、标签，并评估其**重要性**和**影响力**。
*   **AI 服务管理**：
    *   **服务引用模式**：创建可复用的 AI 服务配置，多个分组可以共享同一服务
    *   **双阶段处理**：支持"Single"（单阶段）和"Two-stage"（双阶段：分析+聚合）两种 AI 处理模式
    *   **灵活配置**：支持 OpenAI、DeepSeek、Gemini、OpenAI-compatible 等多种提供商
*   **智能内容过滤**：
    *   **关键词黑名单**：自动屏蔽包含特定关键词的内容
    *   **分类黑名单**：过滤不感兴趣的分类
    *   **数据源黑名单**：排除特定数据源的内容
    *   **AI 预过滤**：AI 会在分析前进行智能判断，进一步过滤无关信息

### 3. 优化的信息流体验

*   **两级内容展示**：
    *   **简报卡片**：以时间线（今天、昨天、更早）分批展示 AI 分析后的内容摘要卡片，一目了然
    *   **详细视图**：点击卡片即可在弹窗中查看完整的 AI 分析、核心要点以及所有信息来源链接
*   **状态管理**：卡片清晰地显示"待阅"、"已读"、"归档"等状态，帮助您高效处理信息
*   **快捷操作**：
    *   批量标记已读、归档、删除
    *   一键导出为 Markdown 笔记
    *   支持按时间、重要性、影响力排序
*   **任务控制**：在插件设置中一键触发后台抓取任务，无需等待定时周期

### 4. 错误追踪与监控

*   **实时错误监控**：主面板右上角显示错误徽章，点击查看错误统计
*   **智能错误统计**：
    *   **按环节分类**：抓取、处理、存储、面板四个环节的错误统计
    *   **按数据源分类**：查看哪些数据源频繁出错
    *   **按日期分类**：了解错误发生的时间趋势
*   **自动禁用机制**：数据源连续失败≥5次且在3天内，系统会自动禁用该数据源
*   **错误清除**：删除或更新数据源时，自动清除相关的历史错误

### 5. 内容去重

*   **智能去重**：自动识别和合并重复的内容，避免信息过载
*   **去重历史**：查看历史去重记录
*   **灵活配置**：可配置去重规则和阈值

### 6. 无缝 Obsidian 集成

*   **一键导出**：在详细视图中，一键将 AI 分析结果和原文链接保存为格式精美的 Markdown 笔记
*   **轻量化设计**：后端服务独立运行，插件本身轻巧，确保不影响 Obsidian 的性能和响应速度
*   **数据本地化**：所有配置和抓取的数据都存储在您的本地设备上，保障数据隐私和安全

## 🚀 如何使用

### 1. 启动后端服务

后端服务是整个系统的大脑，负责数据抓取和 AI 分析。

```bash
# 1. 进入项目根目录
cd /path/to/TrendRadar

# 2. 安装依赖
# 如果遇到权限问题，请使用 sudo pip3 install ...
pip3 install -r requirements.txt
sudo pip3 install apscheduler croniter feedparser

# 3. 启动 API 服务
python3 -m uvicorn api.main:app --host 0.0.0.0 --port 3334
```

服务启动后，您可以通过访问 `http://127.0.0.1:3334` 或 `http://127.0.0.1:3334/docs` (API 文档) 来确认其是否正常运行。

### 2. 安装并配置 Obsidian 插件

1.  将 `obsidian-plugin` 文件夹下的 `main.js`, `manifest.json`, `styles.css` 三个文件复制到您的 Obsidian 仓库的 `.obsidian/plugins/trendradar` 目录下（如果目录不存在，请创建它）。
2.  在 Obsidian 的"第三方插件"设置中，刷新并启用 "TrendRadar AI Assistant" 插件。
3.  进入 TrendRadar 插件的设置页面，按以下顺序配置：

#### 2.1 配置 AI 服务

**首先配置 AI 服务**，这是数据源分组使用 AI 的基础：

*   进入"AI 服务"Tab
*   点击"+ 添加"按钮创建新的 AI 服务：
    *   **服务名称**：如"DeepSeek"、"GPT-4"
    *   **提供商**：选择 OpenAI、DeepSeek、Gemini 等
    *   **API Key**：输入对应服务的 API 密钥
    *   **Base URL**：（可选）自定义 API 端点
    *   **模型名称**：如 `deepseek-chat`, `gpt-4o`
    *   **温度**：控制 AI 输出随机性（0-1）

#### 2.2 配置数据源分组

**创建数据源分组**，将相关的数据源组织在一起：

*   进入"数据源分组"Tab
*   点击"+ 添加"按钮创建分组：
    *   **分组名称**：如"科技新闻"、"技术博客"
    *   **启用状态**：是否启用该分组
*   **配置 AI 处理模式**：
    *   **Single 模式**：使用一个 AI 服务处理整个流程（只需选择"分析服务"）
    *   **Two-stage 模式**：使用两个不同的 AI 服务（分别选择"分析服务"和"聚合服务"）
*   **在分组中管理数据源**：
    *   点击"+ 添加现有数据源"：选择已创建的数据源
    *   点击"+ 创建新数据源"：直接在分组中创建新数据源
    *   支持的数据源类型：**RSS**, **Web**, **Twitter**, **本地文件**

#### 2.3 创建数据源

**支持的四种数据源类型**：

1.  **RSS 订阅**
    *   **名称**：如"36氪"
    *   **RSS URL**：输入 RSS feed 地址
    *   **更新频率**：Cron 表达式，如 `0 */2 * * *`（每2小时）

2.  **网站内容抓取 (Web)**
    *   **名称**：如"某科技博客"
    *   **URL**：要抓取的网站地址
    *   **选择器**：CSS 选择器，如 `.article-title`, `.content`
    *   **更新频率**：Cron 表达式

3.  **Twitter/X 追踪**
    *   **名称**：如"某技术博主"
    *   **用户名**：Twitter 用户名（不含 @）
    *   **更新频率**：Cron 表达式

4.  **本地文件**
    *   **名称**：如"我的笔记库"
    *   **目录路径**：本地文件夹路径
    *   **文件模式**：如 `*.md, *.txt`
    *   **递归扫描**：是否包含子目录

#### 2.4 配置过滤器

*   进入"过滤器"Tab
*   **关键词黑名单**：添加您不感兴趣的关键词（如"娱乐"、"八卦"）
*   **分类黑名单**：过滤不感兴趣的分类
*   **数据源黑名单**：排除特定数据源
*   **最小内容长度**：过滤太短的内容
*   **最小重要性**：只显示高于此重要性的内容
*   **AI 预过滤**：启用 AI 在分析前进行智能过滤

#### 2.5 配置导出路径（可选）

*   在"常规"Tab 中设置"导出路径"
*   导出的笔记将保存到此目录

### 3. 开始使用

*   点击 Obsidian 左侧工具栏的"雷达"图标，即可打开 TrendRadar 面板
*   面板会自动加载最新的信息卡片
*   **使用过滤器**：点击"待阅"、"已读"、"归档"、"All"切换不同状态的内容
*   **操作卡片**：
    *   点击卡片查看详情
    *   点击复选框进行批量操作
    *   使用卡片上的按钮进行标记已读、归档、删除、导出
*   **刷新内容**：点击"刷新"按钮触发后台抓取任务
*   **查看错误**：点击"⚠️"按钮查看错误统计

### 4. 高级功能

#### 4.1 错误监控

*   点击右上角的"⚠️"按钮查看错误统计
*   错误统计包括：
    *   **统计周期**：最近3天的错误
    *   **报错总数**：累计错误数量
    *   **按环节分类**：抓取、处理、存储、面板
    *   **按数据源分类**：每个数据源的失败次数
    *   **按日期分类**：每天的错误数量
*   **自动禁用**：连续失败≥5次且在3天内的数据源会被自动禁用

#### 4.2 批量操作

*   点击卡片左侧的复选框选中多个卡片
*   使用批量操作栏：
    *   标记已读
    *   归档
    *   删除
    *   导出

#### 4.3 排序选项

*   **按时间排序**：最新的内容在前（默认）
*   **按重要性排序**：重要的内容在前
*   **按影响力排序**：影响力大的内容在前

## 🛠️ 技术架构

*   **后端**：Python, FastAPI, Uvicorn
*   **数据抓取**：
    *   `feedparser` (RSS)
    *   `BeautifulSoup` (Web)
    *   `snscrape` (Twitter)
    *   本地文件监听
*   **任务调度**：`apscheduler` (Cron 表达式)
*   **AI 服务管理**：`AIServiceManager`，支持多服务、多模式
*   **错误追踪**：内存队列 + JSON 持久化，支持自动清理和去重
*   **数据存储**：SQLite (通过 `LocalStorageBackend` 实现)
*   **前端 (Obsidian 插件)**：TypeScript, Svelte

## 📊 数据流程

```
数据源 (RSS/Web/Twitter/本地)
    ↓
分组管理 (组织数据源，配置 AI)
    ↓
数据抓取 (定时或手动触发)
    ↓
AI 分析 (Single 或 Two-stage 模式)
    ↓
内容过滤 (关键词/分类/AI 预过滤)
    ↓
去重处理
    ↓
信息展示 (简报卡片 + 详细视图)
    ↓
用户操作 (标记已读/归档/导出)
```

## 🐛 故障排查

### 常见问题

1.  **数据源抓取失败**
    *   检查错误统计（⚠️按钮）查看具体错误信息
    *   验证数据源配置是否正确（URL、选择器等）
    *   某些网站可能需要配置代理或特殊处理

2.  **AI 分析失败**
    *   检查 AI 服务配置（API Key、Base URL、模型名称）
    *   查看 API 服务是否正常运行（`http://127.0.0.1:3334/docs`）
    *   确认 API 密钥有效且有足够配额

3.  **插件无法连接后端**
    *   确认后端服务已启动（`python3 -m uvicorn api.main:app --host 0.0.0.0 --port 3334`）
    *   检查插件设置中的"API URL"是否正确
    *   查看浏览器控制台（F12）的错误信息

4.  **数据源自动禁用**
    *   这是正常行为，连续失败≥5次且在3天内的数据源会被自动禁用
    *   可以在数据源设置中重新启用
    *   查看错误统计了解失败原因

## 🙏 致谢

- 感谢原项目作者 [sansan0/TrendRadar](https://github.com/sansan0/TrendRadar) 提供了优秀的初始框架

## 📄 许可

本项目基于 [GPL-3.0](LICENSE) 许可证开源。
